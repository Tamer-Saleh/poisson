{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/poisson/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../dev/train_ship_segmentations_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d29f5682eb35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mVesselDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     def __init__(self, img_df, train_image_dir=None, valid_image_dir=None, \n\u001b[1;32m      3\u001b[0m                  test_image_dir=None, transform=None, mode='train', binary=True):\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class VesselDataset(Dataset):\n",
    "    def __init__(self, img_df, train_image_dir=None, valid_image_dir=None, \n",
    "                 test_image_dir=None, transform=None, mode='train', binary=True):\n",
    "        self.image_ids = list(img_df.ImageId.unique())\n",
    "        if binary:\n",
    "            self.image_labels = list(map(lambda x: 1 if x > 1 else 0, img_df.counts))\n",
    "        else:\n",
    "            self.image_labels = list(img_df.counts - 1) # Image with no mask has 'count' == 1 in df\n",
    "        self.train_image_dir = train_image_dir\n",
    "        self.valid_image_dir = valid_image_dir\n",
    "        self.test_image_dir = test_image_dir\n",
    "\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        if transform is not None:\n",
    "            self.train_transform = transform\n",
    "        else:\n",
    "            self.train_transform = Compose([\n",
    "                Resize(size=(299,299), interpolation=2),\n",
    "                RandomHorizontalFlip(p=0.5),\n",
    "                RandomVerticalFlip(p=0.5),\n",
    "                RandomBlur(p=0.85, radius=2),\n",
    "                ToTensor(),\n",
    "                Normalize(mean, std) # Apply to all input images\n",
    "            ])\n",
    "        self.valid_transform = Compose([\n",
    "            Resize(size=(299,299), interpolation=2),\n",
    "            RandomBlur(p=1.0, radius=2), # Blur all images\n",
    "            ToTensor(),\n",
    "            Normalize(mean, std) # Apply to all input images\n",
    "        ])\n",
    "        self.test_transform = Compose([\n",
    "            Resize(size=(299,299), interpolation=2),\n",
    "            ToTensor(),\n",
    "            Normalize(mean, std) # Apply to all input images\n",
    "        ])\n",
    "        self.mode = mode\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file_name = self.image_ids[idx]\n",
    "        if self.mode == 'train':\n",
    "            img_path = os.path.join(self.train_image_dir, img_file_name)\n",
    "        elif self.mode == 'valid':\n",
    "            img_path = os.path.join(self.valid_image_dir, img_file_name)\n",
    "        else:\n",
    "            img_path = os.path.join(self.test_image_dir, img_file_name)\n",
    "\n",
    "        #img = imread(img_path)\n",
    "        img = Image.open(img_path)\n",
    "        label = self.image_labels[idx]\n",
    "        if self.mode =='train':\n",
    "            img = self.train_transform(img)\n",
    "        elif self.mode == 'valid':\n",
    "            img = self.valid_transform(img)\n",
    "        else:\n",
    "            img = self.test_transform(img)\n",
    "\n",
    "        if self.mode == 'train' or self.mode == 'valid':\n",
    "            return img, label\n",
    "        else:\n",
    "            return img, img_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(outputs, labels):\n",
    "    preds = torch.argmax(outputs, axis=1)\n",
    "    num_correct = (preds == labels).sum().float()\n",
    "    acc = num_correct / labels.shape[0]\n",
    "    return acc\n",
    "\n",
    "\n",
    "def calculate_precision(outputs, labels):\n",
    "    preds = torch.argmax(outputs, axis=1)\n",
    "    precision = precision_score(outputs, preds)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def calculate_recall(outputs, labels):\n",
    "    preds = torch.argmax(outputs, axis=1)\n",
    "    recall = recall_score(outputs, preds)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def make_confusion_matrix(outputs, labels):\n",
    "    preds = torch.argmax(outputs, axis=1)\n",
    "    confusion = confusion_matrix(labels, outputs)\n",
    "    return confusion\n",
    "\n",
    "\n",
    "def test(model, criterion, test_loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    accs, precisions, recalls = [], [], []\n",
    "    confusion_matrix = np.zeros((2,2))\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            acc = binary_acc(outputs, labels)\n",
    "            accs.append(acc.item())\n",
    "            precision = calculate_precision(outputs, labels)\n",
    "            precisions.append(precision)\n",
    "            recall = calculate_recall(outputs, labels)\n",
    "            recalls.append(recall)\n",
    "            confusion_matrix += make_confusion_matrix(outputs, labels)\n",
    "\n",
    "        \n",
    "    test_loss = np.mean(losses)  # type: float\n",
    "    test_acc = np.mean(accs)\n",
    "    test_precision = np.mean(precisions)\n",
    "    test_recall = np.mean(recalls)\n",
    "    \n",
    "    metrics = {'test_loss': test_loss, 'test_acc': test_acc, \n",
    "               'test_precision': test_precision, 'test_recall': test_recall,\n",
    "               'confusion_matrix': confusion_matrix}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/poisson/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torchvision/models/inception.py:77: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/vessel_classifier_state_dict.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-58344b76fb2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    111\u001b[0m     model = torchvision.models.inception_v3(pretrained=False, progress=True, num_classes=2, \n\u001b[1;32m    112\u001b[0m                                             aux_logits=False)\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_test_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/vessel_classifier_state_dict.pth'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor, Compose, RandomHorizontalFlip, RandomVerticalFlip, Resize, Normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from PIL import Image, ImageFile, ImageFilter\n",
    "\n",
    "\n",
    "def binary_acc(outputs, labels):\n",
    "    preds = torch.argmax(outputs, axis=1)\n",
    "    num_correct = (preds == labels).sum().float()\n",
    "    acc = num_correct / labels.shape[0]\n",
    "    return acc\n",
    "\n",
    "\n",
    "def calculate_precision(outputs, labels):\n",
    "    preds = torch.argmax(outputs, axis=1)\n",
    "    precision = precision_score(outputs, preds)\n",
    "    return precision\n",
    "\n",
    "\n",
    "def calculate_recall(outputs, labels):\n",
    "    preds = torch.argmax(outputs, axis=1)\n",
    "    recall = recall_score(outputs, preds)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def make_confusion_matrix(outputs, labels):\n",
    "    preds = torch.argmax(outputs, axis=1)\n",
    "    confusion = confusion_matrix(labels, outputs)\n",
    "    return confusion\n",
    "\n",
    "\n",
    "def test(model, criterion, test_loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    accs, precisions, recalls = [], [], []\n",
    "    confusion_matrix = np.zeros((2,2))\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            losses.append(loss.item())\n",
    "            acc = binary_acc(outputs, labels)\n",
    "            accs.append(acc.item())\n",
    "            precision = calculate_precision(outputs, labels)\n",
    "            precisions.append(precision)\n",
    "            recall = calculate_recall(outputs, labels)\n",
    "            recalls.append(recall)\n",
    "            confusion_matrix += make_confusion_matrix(outputs, labels)\n",
    "\n",
    "        \n",
    "    test_loss = np.mean(losses)  # type: float\n",
    "    test_acc = np.mean(accs)\n",
    "    test_precision = np.mean(precisions)\n",
    "    test_recall = np.mean(recalls)\n",
    "    \n",
    "    metrics = {'test_loss': test_loss, 'test_acc': test_acc, \n",
    "               'test_precision': test_precision, 'test_recall': test_recall,\n",
    "               'confusion_matrix': confusion_matrix}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def make_test_loader():\n",
    "    ship_dir = '../data/airbus-ship-detection/'\n",
    "    test_image_dir = os.path.join(ship_dir, 'train_v2/')\n",
    "    masks = pd.read_csv(os.path.join(ship_dir,\n",
    "                                     'train_ship_segmentations_v2.csv'))\n",
    "    unique_img_ids = masks.groupby('ImageId').size().reset_index(name='counts')\n",
    "    _, test_ids = train_test_split(unique_img_ids, \n",
    "                     test_size = 0.01, \n",
    "                     stratify = unique_img_ids['counts'],\n",
    "                     random_state=seed\n",
    "                    )\n",
    "    print(\"Test Size: %d\" % len(test_ids))\n",
    "    test_df = pd.merge(unique_img_ids, test_ids)\n",
    "\n",
    "    binary = True\n",
    "    vessel_dataset = VesselDataset(train_df, train_image_dir=train_image_dir, \n",
    "                                   mode='train', binary=binary)\n",
    "\n",
    "    vessel_test_dataset = VesselDataset(test_df, test_image_dir=test_image_dir, \n",
    "                                   mode='test', binary=binary)\n",
    "    \n",
    "    batch_size = 64\n",
    "    shuffle = False\n",
    "    test_loader = DataLoader(\n",
    "                dataset=test_valid_dataset,\n",
    "                shuffle=shuffle,\n",
    "                #num_workers = 0,\n",
    "                batch_size=batch_size,\n",
    "                pin_memory=torch.cuda.is_available()\n",
    "            )\n",
    "    return test_loader\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    state_dict =  r'../data/vessel_classifier_state_dict.pth'\n",
    "    model = torchvision.models.inception_v3(pretrained=False, progress=True, num_classes=2, \n",
    "                                            aux_logits=False)\n",
    "    model.load_state_dict(torch.load(state_dict))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loader = make_test_loader()\n",
    "    metrics = test(model, criterion, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array =  [[1755,   16],\n",
    "          [25,  130]] \n",
    "df_cm = pd.DataFrame(array, index = [i for i in ['Negative', 'Positive']],\n",
    "                  columns = [i for i in ['Negative', 'Positive']])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, cbar=False, fmt=\"d\", cmap='Greys_r', center=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
