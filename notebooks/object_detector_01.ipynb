{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "from torchvision.models.detection.faster_rcnn import FasterRCNN, FastRCNNPredictor\n",
    "from torchvision.transforms import ToTensor, Compose, RandomHorizontalFlip,\\\n",
    "    RandomVerticalFlip, Resize, Normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image, ImageFile, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle2bbox(rle, shape):\n",
    "    '''\n",
    "    rle: run-length encoded image mask, as string\n",
    "    shape: (height, width) of image on which RLE was produced\n",
    "    Returns (x0, y0, x1, y1) tuple describing the bounding box of the rle mask\n",
    "    \n",
    "    Note on image vs np.array dimensions:\n",
    "    \n",
    "        np.array implies the `[y, x]` indexing order in terms of image dimensions,\n",
    "        so the variable on `shape[0]` is `y`, and the variable on the `shape[1]` is `x`,\n",
    "        hence the result would be correct (x0,y0,x1,y1) in terms of image dimensions\n",
    "        for RLE-encoded indices of np.array (which are produced by widely used kernels\n",
    "        and are used in most kaggle competitions datasets)\n",
    "    '''\n",
    "    \n",
    "    a = np.fromiter(rle.split(), dtype=np.uint)\n",
    "    a = a.reshape((-1, 2))  # an array of (start, length) pairs\n",
    "    a[:,0] -= 1  # `start` is 1-indexed\n",
    "    \n",
    "    y0 = a[:,0] % shape[0]\n",
    "    y1 = y0 + a[:,1]\n",
    "    if np.any(y1 > shape[0]):\n",
    "        # got `y` overrun, meaning that there are a pixels in mask on 0 and shape[0] position\n",
    "        y0 = 0\n",
    "        y1 = shape[0]\n",
    "    else:\n",
    "        y0 = np.min(y0)\n",
    "        y1 = np.max(y1)\n",
    "    \n",
    "    x0 = a[:,0] // shape[0]\n",
    "    x1 = (a[:,0] + a[:,1]) // shape[0]\n",
    "    x0 = np.min(x0)\n",
    "    x1 = np.max(x1)\n",
    "    \n",
    "    if x1 > shape[1]:\n",
    "        # just went out of the image dimensions\n",
    "        raise ValueError(\"invalid RLE or image dimensions: x1=%d > shape[1]=%d\" % (\n",
    "            x1, shape[1]\n",
    "        ))\n",
    "\n",
    "    return x0, y0, x1, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(state_dict, num_classes):\n",
    "        inception = torchvision.models.inception_v3(pretrained=False, progress=False, \n",
    "                                                    num_classes=num_classes, aux_logits=False)\n",
    "        inception.load_state_dict(torch.load(state_dict))\n",
    "        modules = list(inception.children())[:-1]\n",
    "        backbone = nn.Sequential(*modules)\n",
    "\n",
    "        for layer in backbone:\n",
    "            for p in layer.parameters():\n",
    "                p.requires_grad = False # Freezes the backbone layers\n",
    "\n",
    "        backbone.out_channels = 2048\n",
    "\n",
    "        anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                           aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "\n",
    "        model = FasterRCNN(backbone, rpn_anchor_generator=anchor_generator,\n",
    "                           box_predictor=FastRCNNPredictor(1024, num_classes))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(rle, shape=(768,768)):\n",
    "    width, height = shape\n",
    "    xmin, ymin, xmax, ymax = rle2bbox(rle, shape)\n",
    "    if xmin >= 0 and xmax <= width and xmin < xmax and \\\n",
    "    ymin >= 0 and ymax <= height and ymin < ymax:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_dir = '../dev/'\n",
    "train_image_dir = os.path.join(ship_dir, 'imgs/')\n",
    "valid_image_dir = os.path.join(ship_dir, 'imgs/')\n",
    "masks = pd.read_csv(os.path.join(ship_dir,\n",
    "                                 'train_ship_segmentations_v2.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = list(masks.groupby('ImageId'))\n",
    "image_ids =  [_id for _id, _ in grp] \n",
    "image_masks = [m['EncodedPixels'].values for _,m in grp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(in_mask_list, N, shape=(768, 768)):\n",
    "    if N == 0:\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
    "        target[\"labels\"] = torch.zeros((0), dtype=torch.int64)\n",
    "        return target\n",
    "    bbox_array = np.empty((N, 4), dtype=np.float32)\n",
    "    labels = torch.ones((N,), dtype=torch.int64)\n",
    "    i = 0\n",
    "    for rle in in_mask_list:\n",
    "        if isinstance(rle, str):\n",
    "            # bbox = tuple(x1, y1, x2, y2)\n",
    "            bbox = rle2bbox(rle, shape)\n",
    "            bbox_array[i,:] = bbox\n",
    "        i += 1\n",
    "    target = {\n",
    "        'boxes': torch.from_numpy(bbox_array),\n",
    "        'labels': labels,\n",
    "    }\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': tensor([[469., 287., 491., 307.],\n",
       "         [ 67., 377.,  84., 386.],\n",
       "         [258., 174., 305., 185.],\n",
       "         [ 72., 386.,  78., 387.],\n",
       "         [331., 178., 369., 197.]]),\n",
       " 'labels': tensor([1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_mask_list = image_masks[3]\n",
    "N = sum([1 for i in in_mask_list if isinstance(i, str)])\n",
    "make_target(in_mask_list, N, shape=(768,768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_dir = '../dev/'\n",
    "train_image_dir = os.path.join(ship_dir, 'imgs/')\n",
    "valid_image_dir = os.path.join(ship_dir, 'imgs/')\n",
    "masks = pd.read_csv(os.path.join(ship_dir,\n",
    "                                 'train_ship_segmentations_v2.csv'))\n",
    "unique_img_ids = masks.groupby('ImageId').reset_index(name='counts')\n",
    "train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.01, \n",
    "                 stratify = unique_img_ids['counts'],\n",
    "                 random_state=seed\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001b1832.jpg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId  counts\n",
       "0  00003e153.jpg    True\n",
       "1  0001124c7.jpg    True\n",
       "2  000155de5.jpg    True\n",
       "3  000194a2d.jpg    True\n",
       "4  0001b1832.jpg    True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.01, \n",
    "                 stratify = unique_img_ids['counts'],\n",
    "                 random_state=seed\n",
    "                )\n",
    "print(\"Train Size: %d\" % len(train_ids))\n",
    "print(\"Valid Size: %d\" % len(valid_ids))\n",
    "train_df = pd.merge(unique_img_ids, train_ids)\n",
    "valid_df = pd.merge(unique_img_ids, valid_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179451, 92763, 165924, 179608, 127945]\n",
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "from typing import Callable, Iterator, Union, Optional, List, Tuple, Dict\n",
    "\n",
    "\n",
    "def get_masks(ship_dir: str, \n",
    "                train_image_dir: Union[str, pathlib.Path], \n",
    "                valid_image_dir: Union[str, pathlib.Path]\n",
    "               ) -> pd.DataFrame:\n",
    "    masks = pd.read_csv(os.path.join(ship_dir,\n",
    "                                     'train_ship_segmentations_v2.csv'\n",
    "                                    )\n",
    "                       )\n",
    "    return masks\n",
    "\n",
    "\n",
    "def is_valid(rle, shape=(768,768)) -> bool:\n",
    "    width, height = shape\n",
    "    xmin, ymin, xmax, ymax = rle2bbox(rle, shape)\n",
    "    if xmin >= 0 and xmax <= width and xmin < xmax and \\\n",
    "    ymin >= 0 and ymax <= height and ymin < ymax:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def filter_masks(masks: pd.DataFrame) -> Tuple[dict, dict]:\n",
    "    grp = list(masks.groupby('ImageId'))\n",
    "    image_names =  {idx: filename for idx, (filename, _) in enumerate(grp)} \n",
    "    image_masks = {idx: m['EncodedPixels'].values for idx, (_, m) in enumerate(grp)}\n",
    "    to_remove = []\n",
    "    for idx, in_mask_list in image_masks.items():\n",
    "        N = sum([1 for i in in_mask_list if isinstance(i, str)])\n",
    "        if N > 0:\n",
    "            for i, rle in enumerate(in_mask_list):\n",
    "                if not is_valid(rle):\n",
    "                    to_remove.append(idx)\n",
    "                    \n",
    "    for idx in to_remove:\n",
    "        del image_names[idx]\n",
    "        del image_masks[idx]\n",
    "    return image_names, image_masks\n",
    "        \n",
    "\n",
    "def get_train_valid_dfs(masks: dict, seed: int = 0) -> Tuple[list, list, list, list]:\n",
    "    ids = np.array(list(masks.keys())).reshape((len(masks),1))\n",
    "    train_ids, valid_ids = train_test_split(\n",
    "         ids, \n",
    "         test_size = 0.01, \n",
    "         random_state=seed\n",
    "        )\n",
    "    train_ids, valid_ids = list(train_ids.flatten()), list(valid_ids.flatten())\n",
    "    train_masks = [masks[idx] for idx in train_ids]\n",
    "    valid_masks = [masks[idx] for idx in valid_ids]\n",
    "    return train_ids, train_masks, valid_ids, valid_masks\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ship_dir = '../dev/'\n",
    "    train_image_dir = os.path.join(ship_dir, 'imgs/')\n",
    "    valid_image_dir = os.path.join(ship_dir, 'imgs/')\n",
    "    masks = get_masks(ship_dir, train_image_dir, valid_image_dir)\n",
    "    image_names, filtered_masks = filter_masks(masks)\n",
    "    train_ids, train_masks, valid_ids, valid_masks = get_train_valid_dfs(\n",
    "        filtered_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190620"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_mask_list = train_masks[0]\n",
    "N = sum([1 for i in in_mask_list if isinstance(i, str)])\n",
    "\n",
    "make_target(in_mask_list, N, shape=(768, 768))['boxes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([420]), array([1189998119991197253])]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.array([[1], [2]])\n",
    "print(list(ids.flatten()))\n",
    "masks = np.array([69, 420, 1189998119991197253])\n",
    "[masks[idx] for idx in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "\n",
    "class Resize:\n",
    "    def __init__(self, \n",
    "                 input_shape = (768, 768), \n",
    "                 output_shape = (299, 299), \n",
    "                 interpolation=2\n",
    "                ):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.interpolation = interpolation\n",
    "        \n",
    "        \n",
    "    def resize_boxes(self, boxes: torch.tensor) -> torch.tensor:\n",
    "        x_orig, y_orig = self.input_shape\n",
    "        x_new, y_new = self.output_shape\n",
    "        x_scale = x_new / x_orig\n",
    "        y_scale = y_new / y_orig\n",
    "        # bbox = tuple(x1, y1, x2, y2)\n",
    "        row_scaler = torch.tensor([x_scale, y_scale, x_scale, y_scale])\n",
    "        boxes_scaled = torch.round(boxes * row_scaler).int() # Converts to new coordinates\n",
    "        return boxes_scaled\n",
    "        \n",
    "        \n",
    "    def __call__(self, image, target) -> Tuple[torch.tensor, dict]:\n",
    "        image = resize(image, size=self.output_shape, interpolation=self.interpolation)\n",
    "        target['boxes'] = self.resize_boxes(target['boxes'])\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed\n"
     ]
    }
   ],
   "source": [
    "def test_resize():\n",
    "    rgb_path = r'../dev/imgs/0002756f7.jpg'\n",
    "    target = {}\n",
    "    target['boxes'] = torch.tensor([[100,100, 200, 200],[10,11,12,13],[14,15,16,17]])\n",
    "    image =  Image.open(rgb_path)\n",
    "    Resize()(image, target)\n",
    "    print(\"test passed\")\n",
    "\n",
    "test_resize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test `VesselDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomBlur:\n",
    "    def __init__(self, p=0.5, radius=2):\n",
    "        self.p = p\n",
    "        self.radius = radius\n",
    "\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        prob = np.random.rand(1)[0]\n",
    "        if prob < self.p:\n",
    "            x = x.filter(ImageFilter.GaussianBlur(self.radius))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VesselDataset(Dataset):\n",
    "    def __init__(self, boxes: Optional[list], image_names: list, train_image_dir=None, valid_image_dir=None, \n",
    "                 test_image_dir=None, transform=None, mode='train', binary=True):\n",
    "        self.boxes = boxes\n",
    "        self.image_names = image_names\n",
    "        self.train_image_dir = train_image_dir\n",
    "        self.valid_image_dir = valid_image_dir\n",
    "        self.test_image_dir = test_image_dir\n",
    "\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        if transform is not None:\n",
    "            self.train_transform = transform\n",
    "        else:\n",
    "            self.train_transform = Compose([\n",
    "                RandomBlur(p=0.95, radius=2),\n",
    "                ToTensor(),\n",
    "                Normalize(mean, std) # Apply to all input images\n",
    "            ])\n",
    "        self.valid_transform = Compose([\n",
    "            RandomBlur(p=1.0, radius=2), # Blur all images\n",
    "            ToTensor(),\n",
    "            Normalize(mean, std) # Apply to all input images\n",
    "        ])\n",
    "        self.test_transform = Compose([\n",
    "            transforms.Resize(size=(299,299), interpolation=2),\n",
    "            ToTensor(),\n",
    "            Normalize(mean, std) # Apply to all input images\n",
    "        ])\n",
    "        self.mode = mode\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.boxes)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file_name = self.image_names[idx]\n",
    "        if self.mode == 'train':\n",
    "            img_path = os.path.join(self.train_image_dir, img_file_name)\n",
    "        elif self.mode == 'valid':\n",
    "            img_path = os.path.join(self.valid_image_dir, img_file_name)\n",
    "        else:\n",
    "            img_path = os.path.join(self.test_image_dir, img_file_name)\n",
    "\n",
    "        #img = imread(img_path)\n",
    "        img = Image.open(img_path)\n",
    "        if self.mode =='train' or self.mode =='valid':\n",
    "            img_boxes = self.boxes[idx]\n",
    "            N = sum([1 for i in img_boxes if isinstance(i, str)])\n",
    "            target = make_target(img_boxes, N, shape=(768, 768))\n",
    "            img, target = Resize(input_shape = (768, 768), \n",
    "                                 output_shape = (299, 299)\n",
    "                                )(img, target)\n",
    "        \n",
    "        if self.mode =='train':\n",
    "            img = self.train_transform(img)\n",
    "            return img, target\n",
    "        elif self.mode == 'valid':\n",
    "            img = self.valid_transform(img)\n",
    "            return img, target\n",
    "        else:\n",
    "            img = self.test_transform(img)\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ids, name in image_names.items():  # for name, age in dictionary.iteritems():  (for Python 2.x)\n",
    "    if name == r'000d26c17.jpg':\n",
    "        print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000d26c17.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 299, 299])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VesselDataset(train_masks, image_names, test_image_dir = r'../dev/imgs', mode='test').__getitem__(32).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from typing import Callable, Iterator, Union, Optional, List, Tuple, Dict\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "\n",
    "def rle2bbox(rle, shape):\n",
    "    '''\n",
    "    rle: run-length encoded image mask, as string\n",
    "    shape: (height, width) of image on which RLE was produced\n",
    "    Returns (x0, y0, x1, y1) tuple describing the bounding box of the rle mask\n",
    "    \n",
    "    Note on image vs np.array dimensions:\n",
    "    \n",
    "        np.array implies the `[y, x]` indexing order in terms of image dimensions,\n",
    "        so the variable on `shape[0]` is `y`, and the variable on the `shape[1]` is `x`,\n",
    "        hence the result would be correct (x0,y0,x1,y1) in terms of image dimensions\n",
    "        for RLE-encoded indices of np.array (which are produced by widely used kernels\n",
    "        and are used in most kaggle competitions datasets)\n",
    "    '''\n",
    "    \n",
    "    a = np.fromiter(rle.split(), dtype=np.uint)\n",
    "    a = a.reshape((-1, 2))  # an array of (start, length) pairs\n",
    "    a[:,0] -= 1  # `start` is 1-indexed\n",
    "    \n",
    "    y0 = a[:,0] % shape[0]\n",
    "    y1 = y0 + a[:,1]\n",
    "    if np.any(y1 > shape[0]):\n",
    "        # got `y` overrun, meaning that there are a pixels in mask on 0 and shape[0] position\n",
    "        y0 = 0\n",
    "        y1 = shape[0]\n",
    "    else:\n",
    "        y0 = np.min(y0)\n",
    "        y1 = np.max(y1)\n",
    "    \n",
    "    x0 = a[:,0] // shape[0]\n",
    "    x1 = (a[:,0] + a[:,1]) // shape[0]\n",
    "    x0 = np.min(x0)\n",
    "    x1 = np.max(x1)\n",
    "    \n",
    "    if x1 > shape[1]:\n",
    "        # just went out of the image dimensions\n",
    "        raise ValueError(\"invalid RLE or image dimensions: x1=%d > shape[1]=%d\" % (\n",
    "            x1, shape[1]\n",
    "        ))\n",
    "\n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "\n",
    "# From: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_decode(mask_rle, shape=(299, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "\n",
    "def is_valid(rle, shape=(768,768)):\n",
    "    width, height = shape\n",
    "    xmin, ymin, xmax, ymax = rle2bbox(rle, shape)\n",
    "    if xmin >= 0 and xmax <= width and xmin < xmax and \\\n",
    "    ymin >= 0 and ymax <= height and ymin < ymax:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def make_target(in_mask_list, N, shape=(768, 768)):\n",
    "    if N == 0:\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
    "        target[\"labels\"] = torch.zeros((0), dtype=torch.int64)\n",
    "        return target\n",
    "    bbox_array = np.empty((N, 4), dtype=np.float32)\n",
    "    labels = torch.ones((N,), dtype=torch.int64)\n",
    "    i = 0\n",
    "    for rle in in_mask_list:\n",
    "        if isinstance(rle, str):\n",
    "            # bbox = tuple(x1, y1, x2, y2)\n",
    "            bbox = rle2bbox(rle, shape)\n",
    "            bbox_array[i,:] = bbox\n",
    "        i += 1\n",
    "    target = {\n",
    "        'boxes': torch.from_numpy(bbox_array),\n",
    "        'labels': labels,\n",
    "    }\n",
    "    return target\n",
    "\n",
    "\n",
    "def get_masks(ship_dir: str, \n",
    "                train_image_dir: Union[str, pathlib.Path], \n",
    "                valid_image_dir: Union[str, pathlib.Path]\n",
    "               ) -> pd.DataFrame:\n",
    "    masks = pd.read_csv(os.path.join(ship_dir,\n",
    "                                     'train_ship_segmentations_v2.csv'\n",
    "                                    )\n",
    "                       )\n",
    "    return masks\n",
    "\n",
    "\n",
    "def is_valid(rle, shape=(768,768)) -> bool:\n",
    "    width, height = shape\n",
    "    xmin, ymin, xmax, ymax = rle2bbox(rle, shape)\n",
    "    if xmin >= 0 and xmax <= width and xmin < xmax and \\\n",
    "    ymin >= 0 and ymax <= height and ymin < ymax:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def filter_masks(masks: pd.DataFrame) -> Tuple[dict, dict]:\n",
    "    grp = list(masks.groupby('ImageId'))\n",
    "    image_names =  {idx: filename for idx, (filename, _) in enumerate(grp)} \n",
    "    image_masks = {idx: m['EncodedPixels'].values for idx, (_, m) in enumerate(grp)}\n",
    "    to_remove = []\n",
    "    for idx, in_mask_list in image_masks.items():\n",
    "        N = sum([1 for i in in_mask_list if isinstance(i, str)])\n",
    "        if N > 0:\n",
    "            for i, rle in enumerate(in_mask_list):\n",
    "                if not is_valid(rle):\n",
    "                    to_remove.append(idx)\n",
    "                    \n",
    "    for idx in to_remove:\n",
    "        del image_names[idx]\n",
    "        del image_masks[idx]\n",
    "    return image_names, image_masks\n",
    "        \n",
    "\n",
    "def get_train_valid_dfs(masks: dict, seed: int = 0) -> Tuple[list, list, list, list]:\n",
    "    ids = np.array(list(masks.keys())).reshape((len(masks),1))\n",
    "    train_ids, valid_ids = train_test_split(\n",
    "         ids, \n",
    "         test_size = 0.01, \n",
    "         random_state=seed\n",
    "        )\n",
    "    train_ids, valid_ids = list(train_ids.flatten()), list(valid_ids.flatten())\n",
    "    train_masks = [masks[idx] for idx in train_ids]\n",
    "    valid_masks = [masks[idx] for idx in valid_ids]\n",
    "    return train_ids, train_masks, valid_ids, valid_masks\n",
    "\n",
    "\n",
    "class Resize:\n",
    "    def __init__(self, \n",
    "                 input_shape = (768, 768), \n",
    "                 output_shape = (299, 299), \n",
    "                 interpolation=2\n",
    "                ):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.interpolation = interpolation\n",
    "        \n",
    "        \n",
    "    def resize_boxes(self, boxes: torch.tensor) -> torch.tensor:\n",
    "        x_orig, y_orig = self.input_shape\n",
    "        x_new, y_new = self.output_shape\n",
    "        x_scale = x_new / x_orig\n",
    "        y_scale = y_new / y_orig\n",
    "        # bbox = tuple(x1, y1, x2, y2)\n",
    "        row_scaler = torch.tensor([x_scale, y_scale, x_scale, y_scale])\n",
    "        boxes_scaled = torch.round(boxes * row_scaler).int() # Converts to new coordinates\n",
    "        return boxes_scaled\n",
    "        \n",
    "        \n",
    "    def __call__(self, image, target) -> Tuple[torch.tensor, dict]:\n",
    "        image = resize(image, size=self.output_shape, interpolation=self.interpolation)\n",
    "        target['boxes'] = self.resize_boxes(target['boxes'])\n",
    "        return image, target\n",
    "    \n",
    "    \n",
    "class RandomBlur:\n",
    "    def __init__(self, p=0.5, radius=2):\n",
    "        self.p = p\n",
    "        self.radius = radius\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        prob = np.random.rand(1)[0]\n",
    "        if prob < self.p:\n",
    "            x = x.filter(ImageFilter.GaussianBlur(self.radius))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class VesselDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 boxes: Optional[list], \n",
    "                 image_names: list, \n",
    "                 train_image_dir=None, \n",
    "                 valid_image_dir=None, \n",
    "                 test_image_dir=None, \n",
    "                 transform=None, \n",
    "                 mode='train', \n",
    "                 binary=True):\n",
    "        self.boxes = boxes\n",
    "        self.image_names = image_names\n",
    "        self.train_image_dir = train_image_dir\n",
    "        self.valid_image_dir = valid_image_dir\n",
    "        self.test_image_dir = test_image_dir\n",
    "\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        if transform is not None:\n",
    "            self.train_transform = transform\n",
    "        else:\n",
    "            self.train_transform = Compose([\n",
    "                RandomBlur(p=0.95, radius=2),\n",
    "                ToTensor(),\n",
    "                Normalize(mean, std) # Apply to all input images\n",
    "            ])\n",
    "        self.valid_transform = Compose([\n",
    "            RandomBlur(p=1.0, radius=2), # Blur all images\n",
    "            ToTensor(),\n",
    "            Normalize(mean, std) # Apply to all input images\n",
    "        ])\n",
    "        self.test_transform = Compose([\n",
    "            transforms.Resize(size=(299,299), interpolation=2),\n",
    "            ToTensor(),\n",
    "            Normalize(mean, std) # Apply to all input images\n",
    "        ])\n",
    "        self.mode = mode\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.boxes)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file_name = self.image_names[idx]\n",
    "        if self.mode == 'train':\n",
    "            img_path = os.path.join(self.train_image_dir, img_file_name)\n",
    "        elif self.mode == 'valid':\n",
    "            img_path = os.path.join(self.valid_image_dir, img_file_name)\n",
    "        else:\n",
    "            img_path = os.path.join(self.test_image_dir, img_file_name)\n",
    "\n",
    "        #img = imread(img_path)\n",
    "        img = Image.open(img_path)\n",
    "        if self.mode =='train' or self.mode =='valid':\n",
    "            img_boxes = self.boxes[idx]\n",
    "            N = sum([1 for i in img_boxes if isinstance(i, str)])\n",
    "            target = make_target(img_boxes, N, shape=(768, 768))\n",
    "            img, target = Resize(input_shape = (768, 768), \n",
    "                                 output_shape = (299, 299)\n",
    "                                )(img, target)\n",
    "            # Make image_id\n",
    "            image_id = torch.tensor([idx])\n",
    "            target[\"image_id\"] = image_id\n",
    "        \n",
    "        if self.mode =='train':\n",
    "            img = self.train_transform(img)\n",
    "            return img, target\n",
    "        elif self.mode == 'valid':\n",
    "            img = self.valid_transform(img)\n",
    "            return img, target\n",
    "        else:\n",
    "            img = self.test_transform(img)\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-fdacc47eed2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalid_image_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mship_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'imgs/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mship_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_image_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_image_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m train_ids, train_masks, valid_ids, valid_masks = get_train_valid_dfs(\n\u001b[1;32m      7\u001b[0m     \u001b[0mfiltered_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-197-9de2fea5b0cc>\u001b[0m in \u001b[0;36mfilter_masks\u001b[0;34m(masks)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfilter_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mgrp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ImageId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0mimage_names\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m{\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mimage_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EncodedPixels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mgroups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \"\"\"\n\u001b[1;32m    437\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assure_grouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mgroups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;34m\"\"\" dict {group name -> group labels} \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mto_groupby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mping\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mgroups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_codes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   4537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4538\u001b[0m         \u001b[0;31m# map to the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4539\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4538\u001b[0m         \u001b[0;31m# map to the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4539\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[1;32m    762\u001b[0m                 )\n\u001b[1;32m    763\u001b[0m             \u001b[0mtaken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     def _assert_take_fillable(\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36m_shallow_copy\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_int64index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mibase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"copy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36m_shallow_copy\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_na\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;31m# Ensure we are not returning an Int64Index with float data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy_with_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_shallow_copy_with_infer\u001b[0;34m(self, values, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTimedeltaIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mis_period_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_period_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m             \u001b[0;31m# Delay import for perf. https://github.com/pandas-dev/pandas/pull/31423\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_period_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPeriodDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0;31m# https://github.com/pandas-dev/pandas/issues/22960\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# avoid passing data to `construct_from_string`. This could\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/pandas/core/dtypes/generic.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# https://github.com/python/mypy/issues/1006\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# error: 'classmethod' used with a non-method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_typ\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ship_dir = '../dev/'\n",
    "train_image_dir = os.path.join(ship_dir, 'imgs/')\n",
    "valid_image_dir = os.path.join(ship_dir, 'imgs/')\n",
    "masks = get_masks(ship_dir, train_image_dir, valid_image_dir)\n",
    "image_names, filtered_masks = filter_masks(masks)\n",
    "train_ids, train_masks, valid_ids, valid_masks = get_train_valid_dfs(\n",
    "    filtered_masks\n",
    ")\n",
    "\n",
    "vessel_dataset = VesselDataset(train_masks, image_names, train_image_dir = r'../dev/imgs', mode='train')\n",
    "\n",
    "vessel_valid_dataset = VesselDataset(valid_masks, image_names, valid_image_dir = r'../dev/imgs', mode='valid')\n",
    "\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "loader = DataLoader(\n",
    "            dataset=vessel_dataset,\n",
    "            shuffle=shuffle,\n",
    "            #num_workers = 0,\n",
    "            batch_size=batch_size,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "            dataset=vessel_valid_dataset,\n",
    "            shuffle=shuffle,\n",
    "            #num_workers = 0,\n",
    "            batch_size=batch_size,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "\n",
    "num_epochs = 30\n",
    "print_freq = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dummy Model and Test IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://discuss.pytorch.org/t/faster-rcnn-with-inceptionv3-backbone-very-slow/91455\n",
    "def make_model(state_dict=None, num_classes=2):\n",
    "        inception = torchvision.models.inception_v3(pretrained=False, progress=False, \n",
    "                                                    num_classes=num_classes, aux_logits=False)\n",
    "        #inception.load_state_dict(torch.load(state_dict))\n",
    "        modules = list(inception.children())[:-1]\n",
    "        backbone = nn.Sequential(*modules)\n",
    "\n",
    "        for layer in backbone:\n",
    "            for p in layer.parameters():\n",
    "                p.requires_grad = False # Freezes the backbone layers\n",
    "\n",
    "        backbone.out_channels = 2048\n",
    "\n",
    "        anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                           aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "\n",
    "        model = FasterRCNN(backbone, rpn_anchor_generator=anchor_generator,\n",
    "                           box_predictor=FastRCNNPredictor(1024, num_classes))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torchvision/models/inception.py:77: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = make_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat `train_one_epoch` and `evaluate` For New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp vision/references/detection/utils.py ./\n",
    "!cp vision/references/detection/transforms.py ./\n",
    "!cp vision/references/detection/coco_eval.py ./\n",
    "!cp vision/references/detection/engine.py ./\n",
    "!cp vision/references/detection/coco_utils.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/miniconda3/envs/poisson/lib/python3.7/site-packages (from pycocotools) (47.3.0.post20200616)\n",
      "Collecting cython>=0.27.3\n",
      "  Using cached Cython-0.29.21-cp37-cp37m-macosx_10_9_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/miniconda3/envs/poisson/lib/python3.7/site-packages (from pycocotools) (3.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/poisson/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/miniconda3/envs/poisson/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/miniconda3/envs/poisson/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/miniconda3/envs/poisson/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.18.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/miniconda3/envs/poisson/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/miniconda3/envs/poisson/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (8.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/miniconda3/envs/poisson/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
      "Requirement already satisfied: six in /opt/miniconda3/envs/poisson/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-macosx_10_9_x86_64.whl size=90488 sha256=3d5863d3d1301f7eea1066a95f84b1df9912c97b06356d1e05afd3e7576ef152\n",
      "  Stored in directory: /Users/richardcorrero/Library/Caches/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: cython, pycocotools\n",
      "Successfully installed cython-0.29.21 pycocotools-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import transforms as T\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dev/imgs/5fe85a9e4.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-1ffd0c55699d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting Training...\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# loop over the dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch %d completed. Running validation...\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/research/poisson/notebooks/engine.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device, epoch, print_freq)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarmup_lr_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/research/poisson/notebooks/utils.py\u001b[0m in \u001b[0;36mlog_every\u001b[0;34m(self, iterable, print_freq, header)\u001b[0m\n\u001b[1;32m    207\u001b[0m             ])\n\u001b[1;32m    208\u001b[0m         \u001b[0mMB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-197-9de2fea5b0cc>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;31m#img = imread(img_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'train'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mimg_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dev/imgs/5fe85a9e4.jpg'"
     ]
    }
   ],
   "source": [
    "ship_dir = '../dev/'\n",
    "train_image_dir = os.path.join(ship_dir, 'imgs/')\n",
    "valid_image_dir = os.path.join(ship_dir, 'imgs/')\n",
    "masks = get_masks(ship_dir, train_image_dir, valid_image_dir)\n",
    "image_names, filtered_masks = filter_masks(masks)\n",
    "train_ids, train_masks, valid_ids, valid_masks = get_train_valid_dfs(\n",
    "    filtered_masks\n",
    ")\n",
    "\n",
    "vessel_dataset = VesselDataset(train_masks, image_names, train_image_dir = r'../dev/imgs', mode='train')\n",
    "\n",
    "vessel_valid_dataset = VesselDataset(valid_masks, image_names, valid_image_dir = r'../dev/imgs', mode='valid')\n",
    "\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "loader = DataLoader(\n",
    "            dataset=vessel_dataset,\n",
    "            shuffle=shuffle,\n",
    "            #num_workers = 0,\n",
    "            batch_size=batch_size,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "            dataset=vessel_valid_dataset,\n",
    "            shuffle=shuffle,\n",
    "            #num_workers = 0,\n",
    "            batch_size=batch_size,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "num_epochs = 30\n",
    "print_freq = 100\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "savepath = r'./sdad'\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-7 # Default should be 1e-5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "print('Starting Training...\\n')\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    train_one_epoch(model, optimizer, loader, device, epoch, print_freq)\n",
    "    print('\\nEpoch %d completed. Running validation...\\n' % (epoch + 1))\n",
    "    evaluate(model, valid_loader, device)\n",
    "    print('\\nSaving Model...\\n')\n",
    "    torch.save(model.state_dict(), savepath)\n",
    "    print('Done.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torchvision/models/inception.py:77: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
      "Train Size: 190620\n",
      "Valid Size: 1926\n",
      "Starting Training...\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"vessel_detector_test_suite.py\", line 382, in <module>\n",
      "    main(savepath, backbone_loadpath)\n",
      "  File \"vessel_detector_test_suite.py\", line 371, in main\n",
      "    train_one_epoch(model, optimizer, loader, device, epoch, print_freq)\n",
      "  File \"/Users/richardcorrero/Projects/research/poisson/notebooks/engine.py\", line 26, in train_one_epoch\n",
      "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
      "  File \"/Users/richardcorrero/Projects/research/poisson/notebooks/utils.py\", line 209, in log_every\n",
      "    for obj in iterable:\n",
      "  File \"/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 475, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"vessel_detector_test_suite.py\", line 266, in __getitem__\n",
      "    img = Image.open(img_path)\n",
      "  File \"/opt/miniconda3/envs/poisson/lib/python3.7/site-packages/PIL/Image.py\", line 2891, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../dev/imgs/54e589d66.jpg'\n"
     ]
    }
   ],
   "source": [
    "!python vessel_detector_test_suite.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
